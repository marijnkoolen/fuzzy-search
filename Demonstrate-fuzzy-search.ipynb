{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fuzzy-search\n",
    "Fuzzy search modules for searching lists of words in low quality OCR and HTR text.\n",
    "\n",
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzy_search.fuzzy_phrase_searcher import FuzzyPhraseSearcher\n",
    "from fuzzy_search.fuzzy_phrase_model import PhraseModel\n",
    "\n",
    "# highger matching thresholds for higher quality OCR/HTR (higher precision, recall should be good anyway)\n",
    "# lower matching thresholds for lower quality OCR/HTR (higher recall, as that's the main problem)\n",
    "\n",
    "config = {\n",
    "    \"char_match_threshold\": 0.6,\n",
    "    \"ngram_threshold\": 0.5,\n",
    "    \"levenshtein_threshold\": 0.6,\n",
    "    \"ignorecase\": False,\n",
    "    \"max_length_variance\": 3,\n",
    "    \"ngram_size\": 2,\n",
    "    \"skip_size\": 2,\n",
    "}\n",
    "\n",
    "# initialize a new searcher instance with the config\n",
    "fuzzy_searcher = FuzzyPhraseSearcher(config)\n",
    "\n",
    "# create a list of domain phrases\n",
    "domain_phrases = [\n",
    "    # terms for the chair and attendants of a meeting\n",
    "    \"PRAESIDE\",\n",
    "    \"PRAESENTIBUS\",\n",
    "    # some weekdays in Latin\n",
    "    \"Veneris\", \n",
    "    \"Mercurii\",\n",
    "    # some date phrase where any date in January 1725 should match\n",
    "    \"den .. Januarii 1725\"\n",
    "]\n",
    "\n",
    "phrase_model = PhraseModel(phrases=domain_phrases)\n",
    "\n",
    "# register the keywords with the searcher\n",
    "fuzzy_searcher.index_phrase_model(phrase_model)\n",
    "\n",
    "# take some example texts: meetings of the Dutch States General in January 1725\n",
    "text1 = \"ie Veucris den 5. Januaris 1725. PR&ASIDE, Den Heere Bentinck. PRASENTIEBUS, De Heeren Jan Welderen , van Dam, Torck , met een extraordinaris Gedeputeerde uyt de Provincie van Gelderlandt. Van Maasdam , vanden Boeizelaar , Raadtpenfionaris van Hoornbeeck , met een extraordinaris Gedeputeerde uyt de Provincie van Hollandt ende Welt-Vrieslandt. Velters, Ockere , Noey; van Hoorn , met een extraordinaris Gedeputeerde uyt de Provincie van Zeelandt. Van Renswoude , van Voor{t. Van Schwartzenbergh, vander Waayen, Vegilin Van I{elmuden. Van Iddekinge ‚ van Tamminga.\"\n",
    "\n",
    "text2 = \"Mercuri: den 10. Jangarii, 1725. ia PRESIDE, Den Heere an Iddekinge. PRA&SENTIBUS, De Heeren /an Welderen , van Dam, van Wynbergen, Torck, met een extraordinaris Gedeputeerde uyt de Provincie van Gelderland. Van Maasdam , Raadtpenfionaris van Hoorn=beeck. Velters, Ockerfe, Noey. Taats van Amerongen, van Renswoude. Vander Waasen , Vegilin, ’ Bentinck, van I(elmaden. Van Tamminga.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `find_matches` method returns match objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match(phrase: \"Veneris\", variant: \"Veneris\",string: \"Veucris\", offset: 3)\n",
      "Match(phrase: \"den .. Januarii 1725\", variant: \"den .. Januarii 1725\",string: \"den 5. Januaris 1725.\", offset: 11)\n",
      "Match(phrase: \"PRAESIDE\", variant: \"PRAESIDE\",string: \"PR&ASIDE,\", offset: 33)\n",
      "Match(phrase: \"PRAESENTIBUS\", variant: \"PRAESENTIBUS\",string: \"PRASENTIEBUS,\", offset: 63)\n"
     ]
    }
   ],
   "source": [
    "# look for matches in the first example text\n",
    "for match in fuzzy_searcher.find_matches(text1):\n",
    "    print(match)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Printing the matches directly yields the following output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match(phrase: \"Veneris\", variant: \"Veneris\",string: \"Veucris\", offset: 3)\n",
      "Match(phrase: \"den .. Januarii 1725\", variant: \"den .. Januarii 1725\",string: \"den 5. Januaris 1725.\", offset: 11)\n",
      "Match(phrase: \"PRAESIDE\", variant: \"PRAESIDE\",string: \"PR&ASIDE,\", offset: 33)\n",
      "Match(phrase: \"PRAESENTIBUS\", variant: \"PRAESENTIBUS\",string: \"PRASENTIEBUS,\", offset: 63)\n"
     ]
    }
   ],
   "source": [
    "# look for matches in the first example text\n",
    "for match in fuzzy_searcher.find_matches(text1):\n",
    "    print(match)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, each match object can generate a JSON representation of the match containing all information:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'phrase': 'Veneris', 'variant': 'Veneris', 'string': 'Veucris', 'offset': 3, 'match_scores': {'char_match': 0.7142857142857143, 'ngram_match': 0.625, 'levenshtein_similarity': 0.7142857142857143}}\n",
      "{'phrase': 'den .. Januarii 1725', 'variant': 'den .. Januarii 1725', 'string': 'den 5. Januaris 1725.', 'offset': 11, 'match_scores': {'char_match': 0.95, 'ngram_match': 0.7619047619047619, 'levenshtein_similarity': 0.8571428571428572}}\n",
      "{'phrase': 'PRAESIDE', 'variant': 'PRAESIDE', 'string': 'PR&ASIDE,', 'offset': 33, 'match_scores': {'char_match': 0.875, 'ngram_match': 0.5555555555555556, 'levenshtein_similarity': 0.6666666666666667}}\n",
      "{'phrase': 'PRAESENTIBUS', 'variant': 'PRAESENTIBUS', 'string': 'PRASENTIEBUS,', 'offset': 63, 'match_scores': {'char_match': 1.0, 'ngram_match': 0.6923076923076923, 'levenshtein_similarity': 0.7692307692307692}}\n"
     ]
    }
   ],
   "source": [
    "# look for matches in the first example text\n",
    "for match in fuzzy_searcher.find_matches(text1):\n",
    "    print(match.json())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the searcher on the second text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'phrase': 'Mercurii', 'variant': 'Mercurii', 'string': 'Mercuri:', 'offset': 0, 'match_scores': {'char_match': 0.875, 'ngram_match': 0.7777777777777778, 'levenshtein_similarity': 0.875}}\n",
      "{'phrase': 'den .. Januarii 1725', 'variant': 'den .. Januarii 1725', 'string': 'den 10. Jangarii, 1725.', 'offset': 9, 'match_scores': {'char_match': 0.95, 'ngram_match': 0.7142857142857143, 'levenshtein_similarity': 0.782608695652174}}\n",
      "{'phrase': 'PRAESIDE', 'variant': 'PRAESIDE', 'string': 'PRESIDE,', 'offset': 36, 'match_scores': {'char_match': 0.875, 'ngram_match': 0.6666666666666666, 'levenshtein_similarity': 0.75}}\n",
      "{'phrase': 'PRAESENTIBUS', 'variant': 'PRAESENTIBUS', 'string': 'PRA&SENTIBUS,', 'offset': 69, 'match_scores': {'char_match': 0.9166666666666666, 'ngram_match': 0.7692307692307693, 'levenshtein_similarity': 0.8461538461538461}}\n"
     ]
    }
   ],
   "source": [
    "# look for matches in the second example text\n",
    "for match in fuzzy_searcher.find_matches(text2):\n",
    "    print(match.json())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match objects can also generate Web Annotation representations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"@context\": \"http://www.w3.org/ns/anno.jsonld\",\n",
      "  \"id\": \"cdf06361-5712-4871-a45a-69395ce6bbd6\",\n",
      "  \"type\": \"Annotation\",\n",
      "  \"motivation\": \"classifying\",\n",
      "  \"created\": \"2020-12-08T10:26:38.601293\",\n",
      "  \"generator\": {\n",
      "    \"id\": \"https://github.com/marijnkoolen/fuzzy-search\",\n",
      "    \"type\": \"Software\",\n",
      "    \"name\": \"FuzzySearcher\"\n",
      "  },\n",
      "  \"target\": {\n",
      "    \"source\": \"urn:republic:3783_0076:page=151:para=4\",\n",
      "    \"selector\": {\n",
      "      \"type\": \"TextPositionSelector\",\n",
      "      \"start\": 0,\n",
      "      \"end\": 8\n",
      "    }\n",
      "  },\n",
      "  \"body\": {\n",
      "    \"type\": \"Dataset\",\n",
      "    \"value\": {\n",
      "      \"match_phrase\": \"Mercurii\",\n",
      "      \"match_variant\": \"Mercurii\",\n",
      "      \"match_string\": \"Mercuri:\",\n",
      "      \"phrase_metadata\": {\n",
      "        \"phrase\": \"Mercurii\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# look for matches in the second example text\n",
    "text2_with_id = {\n",
    "    \"text\": text2,\n",
    "    \"id\": \"urn:republic:3783_0076:page=151:para=4\"\n",
    "}\n",
    "matches = fuzzy_searcher.find_matches(text2_with_id)\n",
    "\n",
    "import json\n",
    "\n",
    "print(json.dumps(matches[0].as_web_anno(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhraseMatch(phrase: \"Makelaars\", variant: \"Makelaars\",string: \"Makelaets\", offset: 3),\n",
       " PhraseMatch(phrase: \"Koffie\", variant: \"Koffie\",string: \"Koffy\", offset: 62)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fuzzy_search.fuzzy_phrase_searcher import FuzzyPhraseSearcher\n",
    "\n",
    "# init searcher with default parameter settings\n",
    "fuzzy_searcher = FuzzyPhraseSearcher()\n",
    "# register phrase you want to search\n",
    "fuzzy_searcher.index_phrases(['Makelaars', 'Tabak', 'Koffie'])\n",
    "\n",
    "# A text with OCR mistakes\n",
    "text = 'De Makelaets sullen verkopen twee balen Tobacco en Javaansche Koffy.'\n",
    "# Find all fuzzy matches\n",
    "fuzzy_searcher.find_matches(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    # these thresholds work when there are few OCR errors\n",
    "    \"char_match_threshold\": 0.8,\n",
    "    \"ngram_threshold\": 0.6,\n",
    "    \"levenshtein_threshold\": 0.8,\n",
    "    # Is upper/lowercase a meaningful signal?\n",
    "    \"ignorecase\": False,\n",
    "    # should matches follow word boundaries?\n",
    "    \"use_word_boundaries\": False,\n",
    "    # for phrases that have variant phrasings\n",
    "    \"include_variants\": False,\n",
    "    # avoid matching with similar but different phrases\n",
    "    \"filter_distractors\": False,\n",
    "    # matching string can be lower/shorter than prhase\n",
    "    \"max_length_variance\": 3,\n",
    "    # higher ngram size allows fewer character differences\n",
    "    \"ngram_size\": 3,\n",
    "    # fewer skips is much faster but less exhaustive\n",
    "    \"skip_size\": 1,\n",
    "}\n",
    "\n",
    "# init searcher, overriding some defaults\n",
    "fuzzy_searcher = FuzzyPhraseSearcher(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhraseMatch(phrase: \"Makelaars\", variant: \"Makelaars\",string: \"Makelaets\", offset: 3),\n",
       " PhraseMatch(phrase: \"Tabak\", variant: \"Tobacco\",string: \"Tobacco\", offset: 40),\n",
       " PhraseMatch(phrase: \"Koffie\", variant: \"Koffie\",string: \"Koffy\", offset: 62)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fuzzy_search.fuzzy_phrase_searcher import FuzzyPhraseSearcher\n",
    "\n",
    "# init searcher with default parameter settings\n",
    "fuzzy_searcher = FuzzyPhraseSearcher({'include_variants': True})\n",
    "# register phrases and optional variants\n",
    "phrases = [\n",
    "    {'phrase': 'Makelaars'},\n",
    "    {'phrase': 'Tabak', 'variants': ['Tobacco']},\n",
    "    {'phrase': 'Koffie'}\n",
    "]\n",
    "\n",
    "fuzzy_searcher.index_phrase_model(phrases)\n",
    "\n",
    "# A text with OCR mistakes\n",
    "text = 'De Makelaets sullen verkopen twee balen Tobacco en Javaansche Koffy.'\n",
    "# Find all fuzzy matches\n",
    "fuzzy_searcher.find_matches(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzy_search.fuzzy_phrase_model import PhraseModel\n",
    "\n",
    "phrase_model = PhraseModel(phrases)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhraseMatch(phrase: \"Makelaars\", variant: \"Makelaars\",string: \"Metselaers\", offset: 3)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A text with a similar but different phrase\n",
    "text = 'De Metselaers sullen verkopen twee zaken cement.'\n",
    "# Find all fuzzy matches\n",
    "fuzzy_searcher.find_matches(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# registering a phrase with a distractor\n",
    "phrases = [{'phrase': 'Makelaars', 'distractors': ['Metselaars']},]\n",
    "\n",
    "fuzzy_searcher.index_phrase_model(phrases)\n",
    "\n",
    "# A text with OCR mistakes\n",
    "text = 'De Metselaers sullen verkopen twee zaken cement.'\n",
    "# Find all fuzzy matches\n",
    "fuzzy_searcher.find_matches(text, filter_distractors=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   3\tMakelaets           \tMakelaars            ['person_role', 'auction_broker']\n",
      "  40\tTobacco             \tTabak                ['auction_good']\n",
      "  62\tKoffy               \tKoffie               ['auction_good']\n"
     ]
    }
   ],
   "source": [
    "fuzzy_searcher = FuzzyPhraseSearcher({'include_variants': True, 'filter_distractors': True})\n",
    "\n",
    "phrases = [\n",
    "    {'phrase': 'Makelaars', 'label': ['person_role', 'auction_broker'], 'distractors': ['Metselaars']},\n",
    "    {'phrase': 'Tabak',     'label': 'auction_good',                    'variants': ['Tobacco']},\n",
    "    {'phrase': 'Koffie',    'label': 'auction_good'},\n",
    "]\n",
    "\n",
    "fuzzy_searcher.index_phrase_model(phrases)\n",
    "\n",
    "# A text with OCR mistakes\n",
    "text = 'De Makelaets sullen verkopen twee balen Tobacco en Javaansche Koffy. ' + \\\n",
    "        'De Metselaers sullen verkopen twee zaken cement.'\n",
    "# Find all fuzzy matches\n",
    "matches = fuzzy_searcher.find_matches(text)\n",
    "for match in matches:\n",
    "    print(f\"{match.offset: >4}\\t{match.string: <20}\\t{match.phrase.phrase_string: <20}\", \n",
    "          match.label_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Auction op Prime Tobaccos. The Executors of the late JOHN BENNETT,\" + \\\n",
    "       \" Tobacco Merchant,will Sell by AUCTION, at HALL'S Sale Room,\" + \\\n",
    "       \" Commercial Buildings, Cork, TUESDAY the 14th October.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Match(start=3, end=12, dist=2, matched='Makelaets')]\n",
      "[Match(start=40, end=45, dist=2, matched='Tobac')]\n",
      "[Match(start=62, end=68, dist=2, matched='Koffy.')]\n"
     ]
    }
   ],
   "source": [
    "from fuzzysearch import find_near_matches\n",
    "\n",
    "phrases = [\n",
    "    {'phrase': 'Makelaars'},\n",
    "    {'phrase': 'Tabak', 'variants': ['Tobacco']},\n",
    "    {'phrase': 'Koffie'}\n",
    "]\n",
    "\n",
    "# A text with OCR mistakes\n",
    "text = 'De Makelaets sullen verkopen twee balen Tobacco en Javaansche Koffy.'\n",
    "for phrase in phrases:\n",
    "    matches = find_near_matches(phrase['phrase'], text, max_l_dist=2)\n",
    "    print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Match(start=203, end=211, dist=4, matched='akei&ers')]\n"
     ]
    }
   ],
   "source": [
    "# Text from Delpher newspaper archive\n",
    "text = \"\"\"n 't Volck inSpanje en Portugacl ten tijdn van de Slag van Almauza , \n",
    "tc geven! W i|l de Intikeoingcn in deExchequer van dc 600000 Ponden, toegeftaert \n",
    "door middel van Lijfrenten te veikoopcn, door de Alakei&ers by na gecompletecrt \n",
    "zijn (die fy Wc'er mei groot propje vetkoopen) werden al itilcke lotekeinngtn te \n",
    "niet geraaeckt door etnCl»uful,die bjr dc Lijfremeo-Bil, \n",
    "dpwclcke nu ftact te pafleren,gevoegt is }\"\"\"\n",
    "\n",
    "print(find_near_matches('Makelaars', text, max_l_dist=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'PhraseMatch', 'phrase': 'Makelaars', 'variant': 'Makelaars', 'string': 'Alakei&ers', 'offset': 201, 'label': None, 'text_id': None, 'match_scores': {'char_match': 0.6666666666666666, 'ngram_match': 0.5, 'levenshtein_similarity': 0.5}}\n"
     ]
    }
   ],
   "source": [
    "fuzzy_searcher = FuzzyPhraseSearcher()\n",
    "fuzzy_searcher.index_phrases(['Makelaars'])\n",
    "matches = fuzzy_searcher.find_matches(text)\n",
    "for match in matches:\n",
    "    print(match.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzy_search.fuzzy_phrase_model import PhraseModel\n",
    "from fuzzy_search.fuzzy_template_searcher import FuzzyTemplateSearcher, FuzzyTemplate\n",
    "\n",
    "phrases = [\n",
    "    {'phrase': 'Makelaars', 'label': ['person_role', 'auction_broker'], 'distractors': ['Metselaars']},\n",
    "    {'phrase': 'Tabak',     'label': 'auction_good',                    'variants': ['Tobacco']},\n",
    "    {'phrase': 'Koffie',    'label': 'auction_good'},\n",
    "]\n",
    "phrase_model = PhraseModel(phrases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template element: auction_broker\n",
      "\tMakelaars      Makelaets         3\n",
      "Template element: auction_good\n",
      "\tTabak          Tobacco          40\n",
      "\tKoffie         Koffy            62\n"
     ]
    }
   ],
   "source": [
    "template = ['auction_broker', 'auction_good']\n",
    "\n",
    "fuzzy_template = FuzzyTemplate(phrase_model, template)\n",
    "template_searcher = FuzzyTemplateSearcher(fuzzy_template, {'include_variants': True, 'filter_distractors': True})\n",
    "\n",
    "# A text with OCR mistakes\n",
    "text = 'De Makelaets sullen verkopen twee balen Tobacco en Javaansche Koffy. ' + \\\n",
    "        'De Metselaers sullen verkopen twee zaken cement.'\n",
    "# Find all fuzzy matches\n",
    "phrase_matches = template_searcher.find_matches(text)\n",
    "template_matches = template_searcher.find_template_matches(phrase_matches)\n",
    "for template_match in template_matches:\n",
    "    for element_match in template_match.element_matches:\n",
    "        print('Template element:', element_match['label'])\n",
    "        for phrase_match in element_match['phrase_matches']:\n",
    "            print(f'\\t{phrase_match.phrase.phrase_string: <15}{phrase_match.string: <15}{phrase_match.offset: >4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = {\n",
    "    'label': 'auction',\n",
    "    'ordered': True,\n",
    "    'type': 'group',\n",
    "    'elements': [\n",
    "        {\n",
    "            'label': 'auction_event',\n",
    "            'ordered': True,\n",
    "            'type': 'group',\n",
    "            'elements': [\n",
    "                {'label': 'auction_broker',   'required': True,  'cardinality': 'single'},\n",
    "                {'label': 'auction_location', 'required': True,  'cardinality': 'single'},\n",
    "                {'label': 'auction_date',     'required': False, 'cardinality': 'single'},\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'label': 'auction_event',\n",
    "            'ordered': False,\n",
    "            'type': 'group',\n",
    "            'elements': [\n",
    "                {'label': 'auction_unit',     'required': False,  'cardinality': 'multi'},\n",
    "                {'label': 'auction_good',     'required': True,  'cardinality': 'multi'},\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
