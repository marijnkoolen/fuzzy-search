{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fuzzy-search\n",
    "Fuzzy search modules for searching lists of words in low quality OCR and HTR text.\n",
    "\n",
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzy_search import FuzzyPhraseSearcher\n",
    "from fuzzy_search import PhraseModel\n",
    "\n",
    "#from fuzzy_search.fuzzy_phrase_searcher import FuzzyPhraseSearcher\n",
    "#from fuzzy_search.fuzzy_phrase_model import PhraseModel\n",
    "\n",
    "# highger matching thresholds for higher quality OCR/HTR (higher precision, recall should be good anyway)\n",
    "# lower matching thresholds for lower quality OCR/HTR (higher recall, as that's the main problem)\n",
    "\n",
    "config = {\n",
    "    \"char_match_threshold\": 0.6,\n",
    "    \"ngram_threshold\": 0.5,\n",
    "    \"levenshtein_threshold\": 0.6,\n",
    "    \"ignorecase\": False,\n",
    "    \"max_length_variance\": 3,\n",
    "    \"ngram_size\": 2,\n",
    "    \"skip_size\": 2,\n",
    "}\n",
    "\n",
    "# create a list of domain phrases\n",
    "domain_phrases = [\n",
    "    # terms for the chair and attendants of a meeting\n",
    "    \"PRAESIDE\",\n",
    "    \"PRAESENTIBUS\",\n",
    "    # some weekdays in Latin\n",
    "    \"Veneris\", \n",
    "    \"Mercurii\",\n",
    "    # some date phrase where any date in January 1725 should match\n",
    "    \"den .. Januarii 1725\"\n",
    "]\n",
    "\n",
    "phrase_model = PhraseModel(phrases=domain_phrases)\n",
    "# initialize a new searcher instance with the config\n",
    "fuzzy_searcher = FuzzyPhraseSearcher(config=config, phrase_model=domain_phrases)\n",
    "\n",
    "# take some example texts: meetings of the Dutch States General in January 1725\n",
    "text1 = \"ie Veucris den 5. Januaris 1725. PR&ASIDE, Den Heere Bentinck. PRASENTIEBUS, De Heeren Jan Welderen , van Dam, Torck , met een extraordinaris Gedeputeerde uyt de Provincie van Gelderlandt. Van Maasdam , vanden Boeizelaar , Raadtpenfionaris van Hoornbeeck , met een extraordinaris Gedeputeerde uyt de Provincie van Hollandt ende Welt-Vrieslandt. Velters, Ockere , Noey; van Hoorn , met een extraordinaris Gedeputeerde uyt de Provincie van Zeelandt. Van Renswoude , van Voor{t. Van Schwartzenbergh, vander Waayen, Vegilin Van I{elmuden. Van Iddekinge ‚ van Tamminga.\"\n",
    "\n",
    "text2 = \"Mercuri: den 10. Jangarii, 1725. ia PRESIDE, Den Heere an Iddekinge. PRA&SENTIBUS, De Heeren /an Welderen , van Dam, van Wynbergen, Torck, met een extraordinaris Gedeputeerde uyt de Provincie van Gelderland. Van Maasdam , Raadtpenfionaris van Hoorn=beeck. Velters, Ockerfe, Noey. Taats van Amerongen, van Renswoude. Vander Waasen , Vegilin, ’ Bentinck, van I(elmaden. Van Tamminga.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `find_matches` method returns match objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhraseMatch(phrase: \"Veneris\", variant: \"Veneris\", string: \"Veucris\", offset: 3, ignorecase: False, levenshtein_similarity: 0.7142857142857143)\n",
      "PhraseMatch(phrase: \"den .. Januarii 1725\", variant: \"den .. Januarii 1725\", string: \"den 5. Januaris 1725\", offset: 11, ignorecase: False, levenshtein_similarity: 0.9)\n",
      "PhraseMatch(phrase: \"PRAESIDE\", variant: \"PRAESIDE\", string: \"PR&ASIDE\", offset: 33, ignorecase: False, levenshtein_similarity: 0.75)\n",
      "PhraseMatch(phrase: \"PRAESENTIBUS\", variant: \"PRAESENTIBUS\", string: \"PRASENTIEBUS\", offset: 63, ignorecase: False, levenshtein_similarity: 0.8333333333333334)\n"
     ]
    }
   ],
   "source": [
    "# look for matches in the first example text\n",
    "for match in fuzzy_searcher.find_matches(text1):\n",
    "    print(match)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Printing the matches directly yields the following output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhraseMatch(phrase: \"Veneris\", variant: \"Veneris\", string: \"Veucris\", offset: 3, ignorecase: False, levenshtein_similarity: 0.7142857142857143)\n",
      "PhraseMatch(phrase: \"den .. Januarii 1725\", variant: \"den .. Januarii 1725\", string: \"den 5. Januaris 1725\", offset: 11, ignorecase: False, levenshtein_similarity: 0.9)\n",
      "PhraseMatch(phrase: \"PRAESIDE\", variant: \"PRAESIDE\", string: \"PR&ASIDE\", offset: 33, ignorecase: False, levenshtein_similarity: 0.75)\n",
      "PhraseMatch(phrase: \"PRAESENTIBUS\", variant: \"PRAESENTIBUS\", string: \"PRASENTIEBUS\", offset: 63, ignorecase: False, levenshtein_similarity: 0.8333333333333334)\n"
     ]
    }
   ],
   "source": [
    "# look for matches in the first example text\n",
    "for match in fuzzy_searcher.find_matches(text1):\n",
    "    print(match)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, each match object can generate a JSON representation of the match containing all information:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'PhraseMatch', 'phrase': 'Veneris', 'variant': 'Veneris', 'string': 'Veucris', 'offset': 3, 'label': None, 'ignorecase': False, 'text_id': None, 'match_scores': {'char_match': 0.7142857142857143, 'ngram_match': 0.625, 'levenshtein_similarity': 0.7142857142857143}}\n",
      "{'type': 'PhraseMatch', 'phrase': 'den .. Januarii 1725', 'variant': 'den .. Januarii 1725', 'string': 'den 5. Januaris 1725', 'offset': 11, 'label': None, 'ignorecase': False, 'text_id': None, 'match_scores': {'char_match': 0.9, 'ngram_match': 0.8095238095238095, 'levenshtein_similarity': 0.9}}\n",
      "{'type': 'PhraseMatch', 'phrase': 'PRAESIDE', 'variant': 'PRAESIDE', 'string': 'PR&ASIDE', 'offset': 33, 'label': None, 'ignorecase': False, 'text_id': None, 'match_scores': {'char_match': 0.875, 'ngram_match': 0.6666666666666666, 'levenshtein_similarity': 0.75}}\n",
      "{'type': 'PhraseMatch', 'phrase': 'PRAESENTIBUS', 'variant': 'PRAESENTIBUS', 'string': 'PRASENTIEBUS', 'offset': 63, 'label': None, 'ignorecase': False, 'text_id': None, 'match_scores': {'char_match': 1.0, 'ngram_match': 0.7692307692307693, 'levenshtein_similarity': 0.8333333333333334}}\n"
     ]
    }
   ],
   "source": [
    "# look for matches in the first example text\n",
    "for match in fuzzy_searcher.find_matches(text1):\n",
    "    print(match.json())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the searcher on the second text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'PhraseMatch', 'phrase': 'Mercurii', 'variant': 'Mercurii', 'string': 'Mercuri', 'offset': 0, 'label': None, 'ignorecase': False, 'text_id': None, 'match_scores': {'char_match': 0.875, 'ngram_match': 0.8888888888888888, 'levenshtein_similarity': 0.875}}\n",
      "{'type': 'PhraseMatch', 'phrase': 'den .. Januarii 1725', 'variant': 'den .. Januarii 1725', 'string': 'den 10. Jangarii, 1725', 'offset': 9, 'label': None, 'ignorecase': False, 'text_id': None, 'match_scores': {'char_match': 0.9, 'ngram_match': 0.7619047619047619, 'levenshtein_similarity': 0.8181818181818181}}\n",
      "{'type': 'PhraseMatch', 'phrase': 'PRAESIDE', 'variant': 'PRAESIDE', 'string': 'PRESIDE', 'offset': 36, 'label': None, 'ignorecase': False, 'text_id': None, 'match_scores': {'char_match': 0.875, 'ngram_match': 0.7777777777777778, 'levenshtein_similarity': 0.875}}\n",
      "{'type': 'PhraseMatch', 'phrase': 'PRAESENTIBUS', 'variant': 'PRAESENTIBUS', 'string': 'PRA&SENTIBUS', 'offset': 69, 'label': None, 'ignorecase': False, 'text_id': None, 'match_scores': {'char_match': 0.9166666666666666, 'ngram_match': 0.8461538461538461, 'levenshtein_similarity': 0.9166666666666666}}\n"
     ]
    }
   ],
   "source": [
    "# look for matches in the second example text\n",
    "for match in fuzzy_searcher.find_matches(text2):\n",
    "    print(match.json())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match objects can also generate Web Annotation representations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"@context\": \"http://www.w3.org/ns/anno.jsonld\",\n",
      "  \"id\": \"f08a7d9a-5b17-4338-b08d-3cafc8276c15\",\n",
      "  \"type\": \"Annotation\",\n",
      "  \"motivation\": \"classifying\",\n",
      "  \"created\": \"2023-04-18T14:10:28.582779\",\n",
      "  \"generator\": {\n",
      "    \"id\": \"https://github.com/marijnkoolen/fuzzy-search\",\n",
      "    \"type\": \"Software\",\n",
      "    \"name\": \"fuzzy-search\"\n",
      "  },\n",
      "  \"target\": {\n",
      "    \"source\": \"urn:republic:3783_0076:page=151:para=4\",\n",
      "    \"selector\": {\n",
      "      \"type\": \"TextPositionSelector\",\n",
      "      \"start\": 0,\n",
      "      \"end\": 7\n",
      "    }\n",
      "  },\n",
      "  \"body\": [\n",
      "    {\n",
      "      \"type\": \"TextualBody\",\n",
      "      \"purpose\": \"tagging\",\n",
      "      \"format\": \"text\",\n",
      "      \"value\": \"Mercurii\"\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"TextualBody\",\n",
      "      \"purpose\": \"highlighting\",\n",
      "      \"format\": \"text\",\n",
      "      \"value\": \"Mercuri\"\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"TextualBody\",\n",
      "      \"purpose\": \"correcting\",\n",
      "      \"format\": \"text\",\n",
      "      \"value\": \"Mercurii\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# look for matches in the second example text\n",
    "text2_with_id = {\n",
    "    \"text\": text2,\n",
    "    \"id\": \"urn:republic:3783_0076:page=151:para=4\"\n",
    "}\n",
    "matches = fuzzy_searcher.find_matches(text2_with_id)\n",
    "\n",
    "import json\n",
    "\n",
    "print(json.dumps(matches[0].as_web_anno(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhraseMatch(phrase: \"Makelaars\", variant: \"Makelaars\",string: \"Makelaets\", offset: 3),\n",
       " PhraseMatch(phrase: \"Koffie\", variant: \"Koffie\",string: \"Koffy\", offset: 62)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fuzzy_search.fuzzy_phrase_searcher import FuzzyPhraseSearcher\n",
    "\n",
    "# init searcher with default parameter settings\n",
    "fuzzy_searcher = FuzzyPhraseSearcher()\n",
    "# register phrase you want to search\n",
    "fuzzy_searcher.index_phrases(['Makelaars', 'Tabak', 'Koffie'])\n",
    "\n",
    "# A text with OCR mistakes\n",
    "text = 'De Makelaets sullen verkopen twee balen Tobacco en Javaansche Koffy.'\n",
    "# Find all fuzzy matches\n",
    "fuzzy_searcher.find_matches(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    # these thresholds work when there are few OCR errors\n",
    "    \"char_match_threshold\": 0.8,\n",
    "    \"ngram_threshold\": 0.6,\n",
    "    \"levenshtein_threshold\": 0.8,\n",
    "    # Is upper/lowercase a meaningful signal?\n",
    "    \"ignorecase\": False,\n",
    "    # should matches follow word boundaries?\n",
    "    \"use_word_boundaries\": False,\n",
    "    # for phrases that have variant phrasings\n",
    "    \"include_variants\": False,\n",
    "    # avoid matching with similar but different phrases\n",
    "    \"filter_distractors\": False,\n",
    "    # matching string can be lower/shorter than prhase\n",
    "    \"max_length_variance\": 3,\n",
    "    # higher ngram size allows fewer character differences\n",
    "    \"ngram_size\": 3,\n",
    "    # fewer skips is much faster but less exhaustive\n",
    "    \"skip_size\": 1,\n",
    "}\n",
    "\n",
    "# init searcher, overriding some defaults\n",
    "fuzzy_searcher = FuzzyPhraseSearcher(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhraseMatch(phrase: \"Makelaars\", variant: \"Makelaars\",string: \"Makelaets\", offset: 3),\n",
       " PhraseMatch(phrase: \"Tabak\", variant: \"Tobacco\",string: \"Tobacco\", offset: 40),\n",
       " PhraseMatch(phrase: \"Koffie\", variant: \"Koffie\",string: \"Koffy\", offset: 62)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fuzzy_search.fuzzy_phrase_searcher import FuzzyPhraseSearcher\n",
    "\n",
    "# init searcher with default parameter settings\n",
    "fuzzy_searcher = FuzzyPhraseSearcher({'include_variants': True})\n",
    "# register phrases and optional variants\n",
    "phrases = [\n",
    "    {'phrase': 'Makelaars'},\n",
    "    {'phrase': 'Tabak', 'variants': ['Tobacco']},\n",
    "    {'phrase': 'Koffie'}\n",
    "]\n",
    "\n",
    "fuzzy_searcher.index_phrase_model(phrases)\n",
    "\n",
    "# A text with OCR mistakes\n",
    "text = 'De Makelaets sullen verkopen twee balen Tobacco en Javaansche Koffy.'\n",
    "# Find all fuzzy matches\n",
    "fuzzy_searcher.find_matches(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzy_search.fuzzy_phrase_model import PhraseModel\n",
    "\n",
    "phrase_model = PhraseModel(phrases)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhraseMatch(phrase: \"Makelaars\", variant: \"Makelaars\",string: \"Metselaers\", offset: 3)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A text with a similar but different phrase\n",
    "text = 'De Metselaers sullen verkopen twee zaken cement.'\n",
    "# Find all fuzzy matches\n",
    "fuzzy_searcher.find_matches(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# registering a phrase with a distractor\n",
    "phrases = [{'phrase': 'Makelaars', 'distractors': ['Metselaars']},]\n",
    "\n",
    "fuzzy_searcher.index_phrase_model(phrases)\n",
    "\n",
    "# A text with OCR mistakes\n",
    "text = 'De Metselaers sullen verkopen twee zaken cement.'\n",
    "# Find all fuzzy matches\n",
    "fuzzy_searcher.find_matches(text, filter_distractors=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   3\tMakelaets           \tMakelaars            ['person_role', 'auction_broker']\n",
      "  40\tTobacco             \tTabak                ['auction_good']\n",
      "  62\tKoffy               \tKoffie               ['auction_good']\n"
     ]
    }
   ],
   "source": [
    "fuzzy_searcher = FuzzyPhraseSearcher({'include_variants': True, 'filter_distractors': True})\n",
    "\n",
    "phrases = [\n",
    "    {'phrase': 'Makelaars', 'label': ['person_role', 'auction_broker'], 'distractors': ['Metselaars']},\n",
    "    {'phrase': 'Tabak',     'label': 'auction_good',                    'variants': ['Tobacco']},\n",
    "    {'phrase': 'Koffie',    'label': 'auction_good'},\n",
    "]\n",
    "\n",
    "fuzzy_searcher.index_phrase_model(phrases)\n",
    "\n",
    "# A text with OCR mistakes\n",
    "text = 'De Makelaets sullen verkopen twee balen Tobacco en Javaansche Koffy. ' + \\\n",
    "        'De Metselaers sullen verkopen twee zaken cement.'\n",
    "# Find all fuzzy matches\n",
    "matches = fuzzy_searcher.find_matches(text)\n",
    "for match in matches:\n",
    "    print(f\"{match.offset: >4}\\t{match.string: <20}\\t{match.phrase.phrase_string: <20}\", \n",
    "          match.label_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Auction op Prime Tobaccos. The Executors of the late JOHN BENNETT,\" + \\\n",
    "       \" Tobacco Merchant,will Sell by AUCTION, at HALL'S Sale Room,\" + \\\n",
    "       \" Commercial Buildings, Cork, TUESDAY the 14th October.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Match(start=3, end=12, dist=2, matched='Makelaets')]\n",
      "[Match(start=40, end=45, dist=2, matched='Tobac')]\n",
      "[Match(start=62, end=68, dist=2, matched='Koffy.')]\n"
     ]
    }
   ],
   "source": [
    "from fuzzysearch import find_near_matches\n",
    "\n",
    "phrases = [\n",
    "    {'phrase': 'Makelaars'},\n",
    "    {'phrase': 'Tabak', 'variants': ['Tobacco']},\n",
    "    {'phrase': 'Koffie'}\n",
    "]\n",
    "\n",
    "# A text with OCR mistakes\n",
    "text = 'De Makelaets sullen verkopen twee balen Tobacco en Javaansche Koffy.'\n",
    "for phrase in phrases:\n",
    "    matches = find_near_matches(phrase['phrase'], text, max_l_dist=2)\n",
    "    print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Match(start=203, end=211, dist=4, matched='akei&ers')]\n"
     ]
    }
   ],
   "source": [
    "# Text from Delpher newspaper archive\n",
    "text = \"\"\"n 't Volck inSpanje en Portugacl ten tijdn van de Slag van Almauza , \n",
    "tc geven! W i|l de Intikeoingcn in deExchequer van dc 600000 Ponden, toegeftaert \n",
    "door middel van Lijfrenten te veikoopcn, door de Alakei&ers by na gecompletecrt \n",
    "zijn (die fy Wc'er mei groot propje vetkoopen) werden al itilcke lotekeinngtn te \n",
    "niet geraaeckt door etnCl»uful,die bjr dc Lijfremeo-Bil, \n",
    "dpwclcke nu ftact te pafleren,gevoegt is }\"\"\"\n",
    "\n",
    "print(find_near_matches('Makelaars', text, max_l_dist=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'PhraseMatch', 'phrase': 'Makelaars', 'variant': 'Makelaars', 'string': 'Alakei&ers', 'offset': 201, 'label': None, 'text_id': None, 'match_scores': {'char_match': 0.6666666666666666, 'ngram_match': 0.5, 'levenshtein_similarity': 0.5}}\n"
     ]
    }
   ],
   "source": [
    "fuzzy_searcher = FuzzyPhraseSearcher()\n",
    "fuzzy_searcher.index_phrases(['Makelaars'])\n",
    "matches = fuzzy_searcher.find_matches(text)\n",
    "for match in matches:\n",
    "    print(match.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzy_search.fuzzy_phrase_model import PhraseModel\n",
    "from fuzzy_search.fuzzy_template_searcher import FuzzyTemplateSearcher, FuzzyTemplate\n",
    "\n",
    "phrases = [\n",
    "    {'phrase': 'Makelaars', 'label': ['person_role', 'auction_broker'], 'distractors': ['Metselaars']},\n",
    "    {'phrase': 'Tabak',     'label': 'auction_good',                    'variants': ['Tobacco']},\n",
    "    {'phrase': 'Koffie',    'label': 'auction_good'},\n",
    "]\n",
    "phrase_model = PhraseModel(phrases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template element: auction_broker\n",
      "\tMakelaars      Makelaets         3\n",
      "Template element: auction_good\n",
      "\tTabak          Tobacco          40\n",
      "\tKoffie         Koffy            62\n"
     ]
    }
   ],
   "source": [
    "template = ['auction_broker', 'auction_good']\n",
    "\n",
    "fuzzy_template = FuzzyTemplate(phrase_model, template)\n",
    "template_searcher = FuzzyTemplateSearcher(fuzzy_template, {'include_variants': True, 'filter_distractors': True})\n",
    "\n",
    "# A text with OCR mistakes\n",
    "text = 'De Makelaets sullen verkopen twee balen Tobacco en Javaansche Koffy. ' + \\\n",
    "        'De Metselaers sullen verkopen twee zaken cement.'\n",
    "# Find all fuzzy matches\n",
    "phrase_matches = template_searcher.find_matches(text)\n",
    "template_matches = template_searcher.find_template_matches(phrase_matches)\n",
    "for template_match in template_matches:\n",
    "    for element_match in template_match.element_matches:\n",
    "        print('Template element:', element_match['label'])\n",
    "        for phrase_match in element_match['phrase_matches']:\n",
    "            print(f'\\t{phrase_match.phrase.phrase_string: <15}{phrase_match.string: <15}{phrase_match.offset: >4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = {\n",
    "    'label': 'auction',\n",
    "    'ordered': True,\n",
    "    'type': 'group',\n",
    "    'elements': [\n",
    "        {\n",
    "            'label': 'auction_event',\n",
    "            'ordered': True,\n",
    "            'type': 'group',\n",
    "            'elements': [\n",
    "                {'label': 'auction_broker',   'required': True,  'cardinality': 'single'},\n",
    "                {'label': 'auction_location', 'required': True,  'cardinality': 'single'},\n",
    "                {'label': 'auction_date',     'required': False, 'cardinality': 'single'},\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'label': 'auction_event',\n",
    "            'ordered': False,\n",
    "            'type': 'group',\n",
    "            'elements': [\n",
    "                {'label': 'auction_unit',     'required': False,  'cardinality': 'multi'},\n",
    "                {'label': 'auction_good',     'required': True,  'cardinality': 'multi'},\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ie' 0 2 1\n",
      "'Veucris' 3 7 15\n",
      "'den' 11 3 3\n",
      "'5.' 15 2 1\n",
      "'Januaris' 18 8 18\n",
      "'1725.' 27 5 9\n",
      "'PR&ASIDE,' 33 9 21\n",
      "'Den' 43 3 3\n",
      "'Heere' 47 5 9\n",
      "'Bentinck.' 53 9 21\n",
      "'PRASENTIEBUS,' 63 13 33\n",
      "'De' 77 2 1\n",
      "'Heeren' 80 6 12\n",
      "'Jan' 87 3 3\n",
      "'Welderen' 91 8 18\n",
      "',' 100 1 0\n",
      "'van' 102 3 3\n",
      "'Dam,' 106 4 6\n",
      "'Torck' 111 5 9\n",
      "',' 117 1 0\n",
      "'met' 119 3 3\n",
      "'een' 123 3 3\n",
      "'extraordinaris' 127 14 36\n",
      "'Gedeputeerde' 142 12 30\n",
      "'uyt' 155 3 3\n",
      "'de' 159 2 1\n",
      "'Provincie' 162 9 21\n",
      "'van' 172 3 3\n",
      "'Gelderlandt.' 176 12 30\n",
      "'Van' 189 3 3\n",
      "'Maasdam' 193 7 15\n",
      "',' 201 1 0\n",
      "'vanden' 203 6 12\n",
      "'Boeizelaar' 210 10 24\n",
      "',' 221 1 0\n",
      "'Raadtpenfionaris' 223 16 42\n",
      "'van' 240 3 3\n",
      "'Hoornbeeck' 244 10 24\n",
      "',' 255 1 0\n",
      "'met' 257 3 3\n",
      "'een' 261 3 3\n",
      "'extraordinaris' 265 14 36\n",
      "'Gedeputeerde' 280 12 30\n",
      "'uyt' 293 3 3\n",
      "'de' 297 2 1\n",
      "'Provincie' 300 9 21\n",
      "'van' 310 3 3\n",
      "'Hollandt' 314 8 18\n",
      "'ende' 323 4 6\n",
      "'Welt-Vrieslandt.' 328 16 42\n",
      "'Velters,' 345 8 18\n",
      "'Ockere' 354 6 12\n",
      "',' 361 1 0\n",
      "'Noey;' 363 5 9\n",
      "'van' 369 3 3\n",
      "'Hoorn' 373 5 9\n",
      "',' 379 1 0\n",
      "'met' 381 3 3\n",
      "'een' 385 3 3\n",
      "'extraordinaris' 389 14 36\n",
      "'Gedeputeerde' 404 12 30\n",
      "'uyt' 417 3 3\n",
      "'de' 421 2 1\n",
      "'Provincie' 424 9 21\n",
      "'van' 434 3 3\n",
      "'Zeelandt.' 438 9 21\n",
      "'Van' 448 3 3\n",
      "'Renswoude' 452 9 21\n",
      "',' 462 1 0\n",
      "'van' 464 3 3\n",
      "'Voor{t.' 468 7 15\n",
      "'Van' 476 3 3\n",
      "'Schwartzenbergh,' 480 16 42\n",
      "'vander' 497 6 12\n",
      "'Waayen,' 504 7 15\n",
      "'Vegilin' 512 7 15\n",
      "'Van' 520 3 3\n",
      "'I{elmuden.' 524 10 24\n",
      "'Van' 535 3 3\n",
      "'Iddekinge' 539 9 21\n",
      "'‚' 549 1 0\n",
      "'van' 551 3 3\n",
      "'Tamminga.' 555 9 21\n"
     ]
    }
   ],
   "source": [
    "from fuzzy_search.tokenization.token import Tokenizer\n",
    "from fuzzy_search.tokenization.string import text2skipgrams\n",
    "from fuzzy_search.tokenization.string import SkipGram\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "doc1 = tokenizer.tokenize(text1)\n",
    "for token in doc1:\n",
    "    if token.n in fuzzy_searcher.phrase_model.token_in_phrase:\n",
    "        print(token)\n",
    "    skip_matches = fuzzy_searcher.find_skipgram_token_matches({'text': token.normalised_string})\n",
    "    skips = text2skipgrams(token.normalised_string, ngram_size=config['ngram_size'], skip_size=config['skip_size'])\n",
    "    num_skips = len([skip for skip in skips])\n",
    "    print(token, token.char_index, len(token.normalised_string), num_skips)\n",
    "    for phrase in skip_matches.match_offsets:\n",
    "        doc_skips = []\n",
    "        for skipgram in skip_matches.match_skipgrams[phrase]:\n",
    "            doc_skip = SkipGram(skipgram.string, skipgram.offset + token.char_index, skipgram.length)\n",
    "            doc_skips.append(doc_skip)\n",
    "            #print(skipgram.string, skipgram.offset)\n",
    "            #skipgram.offset += token.char_index\n",
    "        print('\\t', phrase.phrase_string)\n",
    "        print('\\t\\t', skip_matches.match_set[phrase])\n",
    "        print('\\t\\t', skip_matches.match_offsets[phrase])\n",
    "        print('\\t\\t', [(skipgram.string, skipgram.offset, skipgram.length) for skipgram in doc_skips])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_size = 2\n",
    "skip_size = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
